# 5.7.1 SISD、SIMD、MIMD的基本概念

常规的单处理器属于SISD，而常规的多处理器属于MIMD

## 单指令流单数据流(SISD)结构

SISD是传统的串行计算机结构, 这种计算机通常**仅包含一个处理器和一个存储器**, **处理器在一段时间内仅执行一条指令**, 按指令流规定的**顺序串行**执行指令流中的若干指令

为了提高速度, SISD计算机采用**流水线**的方式
因此, SISD处理器有时会设置多个功能部件, 并且采用**多模块交叉方式**组织存储器
## 单指令流多数据流(SIMD)结构

一个指令流同时对多个数据流进行处理, 一般称为**数据级并行技术**
这种结构的计算机通常由**一个指令控制部件、多个处理单元组成**. 每个处理单元虽然执行的都是同一条指令, 但是每个单元都有自己的地址寄存器, 这样每个单元就都有不同的数据地
因此，**不同处理单元执行的同一条指令所处理的数据是不同的**

一个顺序应用程序被编译后, 既可能按SISD组织并运行于串行硬件上, 又可能按SIMD组织并运行于并行硬件上
+ SIMD在使用for循环处理数组时最有效: 一条分别对16对数据进行运算的SIMD指令若在16个ALU中同时运算, 则只需要一次运算时间就能完成运算
+ SIMD在使用case或switch语句时效率最低, 此时每个执行单元必须根据不同的数据执行不同的操作
## 多指令流单数据流（MISD）结构

MISD是指同时执行多条指令, 处理同一个数据, **实际上不存在这样的计算机**
## 多指令流多数据流(MIMD)结构

MIMD是指同时执行多条指令分别处理多个不同的数据
MIMD分为**多计算机系统和多处理器系统**
+ 多计算机系统: 每个计算机节点都具有各自的私有存储器, 并且具有独立的主存地址空间, **不能通过存取指令来访问不同节点的私有存储器**, 而要通过消息传递进行数据传送, 也称消息传递MIMD
+ 多处理器系统: 共享存储多处理器(SMP)系统的简称，**它具有共享的单一地址空间，通过存取指令来访问系统中的所有存储器，也称共享存储MIMD**

向量处理器是SIMD的变体, 是一种实现了直接操作一维数组(向量)指令集的CPU, 串行处理器只能处理单一数据集
其基本理念是将从存储器中收集的一组数据按顺序放到一组向量寄存器中，然后以流水化的方式对它们依次操作, 最后将结果写回寄存器
向量处理器在特定工作环境中极大地提升了性能, 尤其是在数值模拟或者相似的领域中
SIMD和MIMD是两种并行计算模式, 其中SIMD是一种**数据级**并行模式, 而MIMD是一种并行程度更高的**线程级**并行或线程级以上并行计算模式
# 5.7.2 硬件多线程的基本概念

在传统CPU中, 线程的切换包含一系列开销, **频繁地切换会极大影响系统的性能**
为了减少线程切换过程中的开销, 便诞生了硬件多线程. 在支持硬件多线程的CPU中, **必须为每个线程提供单独的通用寄存器组、单独的程序计数器等**, 线程的切换只需激活选中的寄存器, 从而省略了与存储器数据交换的环节, 大大减少了线程切换的开销。

![[三种硬件多线程方式的调度示例.png]]
## 细粒度多线程

> 多个线程之间轮流交叉执行指令, 多个线程之间的指令是不相关的, 可以乱序并行执行
> 在这种方式下处理器能在每个时钟周期切换线程


## 粗粒度多线程

> 连续几个时钟周期都执行同一线程的指令序列, 仅在当前线程出现了较大开销的阻塞时, 才切换线程, 如Cache缺失. 
> 在这种方式下当发生流水线阻塞时, 必须清除被阻塞的流水线, 新线程的指令开始执行前需要重载流水线
> 因此，线程切换的开销比细粒度多线程更大

>[!attention] **上述两种多线程技术都实现了指令级并行, 但线程级不并行**

## 同时多线程(SMT)

> 它在实现指令级并行的同时, 实现线程级并行, 也就是说, 它在同一个时钟周期中，发射多个不同线程中的多条指令执行

>[!info] Intel处理器中的超线程(Hyper-threading)就是SMT, 即在一个处理器或单个核中设置了**两套线程状态部件, 共享高速缓存和功能部件**

# 5.7.3 多核处理器的基本概念

![[不共享Cache的双核CPU结构.png]]

在多核计算机系统中, 如要充分发挥硬件的性能, 必须采用多线程, 使得每个核在同一时刻都有线程在执行
+ 多核上的多个线程是在物理上并行执行的, 是真正意义上的并行执行, 在同一时刻有多个线程在并行执行
+ 单核上的多线程是一种多线程交错执行实际不在同一时刻只有一个线程在执行

# 5.7.4 共享内存多处理器的基本概念

**具有共享的单一物理地址空间**的多处理器称为共享内存多处理器(SMP)
处理器通过存储器中的共享变量互相通信, 所有处理器都能通过存取指令访问存储器的任何位置
>[!attention]这些系统共享同一个物理地址空间, 它们仍然可在自己的虚拟地址空间中单独地运行程序


单一地址空间的多处理器有两种类型：
+ 统一存储访问(UMA)多处理器: 每个处理器对所有存储单元的访问时间是大致相同的, 即**访问时间与哪个处理器提出访存请求及访问哪个字无关**
+ 非统一存储访问(NUMA)多处理器: 某些存储器的访存速度要比其他的快, 具体取决于哪个处理器提出访问请求及访问哪个字, 这是由于**主存被分割分配给了不同处理器**

早期的计算机, 内存控制器没有整合进CPU, 访存操作需要经过北桥芯片(集成了内存控制器, 并与内存相连), CPU通过前端总线和北桥芯片相连, 这就是UMA构架
随着CPU性能提升由提高主频转到增加CPU数量(多核、多CPU), 越来越多的CPU对前端总线的争用使得**前端总线成为瓶颈**
为了消除UMA架构的瓶颈, NUMA构架诞生,

>[!info] NUMA架构
>内存控制器被集成到CPU内部, 每个CPU都有独立的内存控制器, 每个CPU都独立连接到一部分内存, CPU直连的这部分内存被称为本地内存
>CPU之间通过QPI总线相连。CPU可以通过QPI总线访问其他CPU的远程内存
>
>与UMA架构不同的是, 在NUMA架构下, **内存的访问出现了本地和远程的区别, 访问本地内存明显要快于访问远程内存**
>
>由于可能出现多个处理器同时访问同一共享变量的情况, 在操作共享变量时需要进行同步, 否则, 一个处理器可能在其他处理器尚未完成对共享变量的修改时, 就开始使用该变量
>常用方法是通过**对共享变量加锁**的方式来控制对共享变量互斥访问
>在一个时刻只能有一个处理器获得锁, 其他需要操作该共享变量的处理器必须等待, 直到该处理器解锁该变量为止
>
 [[3.5 高速缓冲存储器#3.5.5 Cache的一致性问题]]讨论的一致性是指Cache与主存之间的数据一致性. 在UMA构架的多处理器中, 所有CPU共享同一内存空间, 每个CPU的Cache都是共享内存中的一部分副本, 因此**多核系统的Cache一致性既包括Cache和内存之间的一致性, 还包括各CPU的Cache之间的一致性**
 **对内存同一位置的数据, 不同CPU的Cache不应该有不一致的内容**